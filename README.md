# 📚 프로젝트 소개

본 프로젝트는 **사용자의 자연어 입력을 받아 AI가 텍스트를 생성하는 서비스**를 구축하는 것을 목표로 합니다.  
간단한 웹 인터페이스를 통해 질문을 입력하고, AI 모델이 자연어로 답변을 생성하는 시스템입니다.

---

## 🚩 문제 인식

초기에는 **Gemma 2B** 모델을 사용하여 서비스를 구성했습니다.  
하지만 다음과 같은 한계에 직면했습니다:

- **느린 처리 속도**:  
  Gemma 2B는 주로 **CPU 기반**으로 구동되었기 때문에, 질문을 입력한 후 답변을 받기까지 시간이 매우 오래 걸렸습니다.
- **언어 지원 한계**:  
  영어 및 중국어에 대한 대응력이 중요한 상황에서,  
  Gemma 2B는 **다국어 성능이 제한적**이었고, 긴 문장이나 복잡한 요청을 제대로 처리하지 못하는 경우가 발생했습니다.

**결론적으로**,  
**속도 문제**와 **언어 대응 한계**를 모두 극복할 수 있는 대안이 필요했습니다.

---

## 🛠️ 솔루션: OpenChat 3.5 도입

문제 해결을 위해 선택한 모델은 **OpenChat 3.5**입니다.  
OpenChat 3.5는 **영어**와 **중국어**에 대해 매우 강력한 문맥 이해와 답변 생성을 제공합니다.

물론, OpenChat 3.5는  
**한국어 최적화 수준이 상대적으로 낮아** 일부 답변이 부자연스럽게 생성될 수 있습니다.  
하지만 프로젝트의 중장기 목표가 **다국어 지원 확장(특히 영어/중국어)**에 있기 때문에,  
전체적인 전략을 고려할 때 OpenChat 3.5가 더 적합한 선택이었습니다.

**요약하면**:  
> 한국어만 본다면 아쉬움이 있지만,  
> 영어·중국어 대응성과 장기 확장성을 고려해 OpenChat 3.5를 선택했습니다.

---

## ⚙️ 성능 최적화 방법 (코드 기반 설명)

OpenChat 3.5는 **7B 규모**의 대형 모델이기 때문에, 그대로 사용하면  
오히려 속도와 메모리 문제가 발생할 수 있습니다.  
이를 해결하기 위해 다음과 같은 최적화 방법을 적용했습니다:

- **4bit 양자화 (`load_in_4bit=True`)**  
  모델 파라미터를 원래 16bit나 32bit 대신 4bit 크기로 압축하여,  
  **메모리 사용량을 약 1/4 수준**으로 줄였습니다.  
  (즉, 훨씬 작은 용량으로 모델을 메모리에 올릴 수 있습니다.)

- **FP16 연산 최적화 (`torch_dtype=torch.float16`)**  
  계산을 32bit 대신 **16bit 부동소수점(FP16)**으로 처리하여,  
  **연산 속도를 2배 가까이 빠르게** 하고, GPU 메모리 부담도 줄였습니다.

- **GPU 우선 배치 (`device_map="auto"`)**  
  모델의 주요 연산을 **GPU로 자동 배치**하여, CPU보다 훨씬 빠른 병렬 연산이 가능하도록 했습니다.

- **메모리 오프로딩 지원 (`offload_folder`)**  
  GPU 메모리가 부족할 경우, 일부 연산을 **디스크나 CPU로 임시 이동(offloading)** 해서,  
  시스템 다운 없이 안정적으로 모델을 운영할 수 있도록 했습니다.

이러한 최적화 덕분에  
**모델 크기가 커졌음에도 불구하고**,  
**실제 응답 속도는 Gemma 2B 사용 당시보다 훨씬 빨라졌습니다.**

---

## 🌟 모델 특징 및 한계

- **장점**:  
  - 영어와 중국어에 대해 **탁월한 문맥 이해**와 **자연스러운 답변 생성** 능력을 보임
  - 대규모 입력이나 긴 대화에 대해서도 **안정적인 응답 품질** 제공
  - 다국어 확장성에 매우 적합한 구조

- **한계**:  
  - **한국어 입력에 대해서는 최적화 수준이 낮아**,  
    일부 문장 구성이나 어색한 표현이 발생할 수 있음

---

## ✨ 요약

> 초기의 Gemma 2B 모델은 느린 속도와 다국어 대응 부족으로 인해 제약이 있었으며,  
> OpenChat 3.5로 전환하고 4bit 양자화, FP16 최적화, 메모리 오프로딩 등의 기법을 적용한 결과,  
> **더 빠르고 안정적이며, 영어·중국어 대응력이 강화된 시스템**을 구축할 수 있었습니다.

